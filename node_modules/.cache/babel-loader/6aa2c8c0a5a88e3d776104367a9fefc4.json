{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { whereImpl } from '../backends/where_impl';\nimport { ENGINE } from '../engine';\nimport { SelectV2 } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assert, assertShapesMatch } from '../util';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { op } from './operation';\nimport { zerosLike } from './tensor_ops';\n/**\n * Returns the truth value of `NOT x` element-wise.\n *\n * ```js\n * const a = tf.tensor1d([false, true], 'bool');\n *\n * a.logicalNot().print();\n * ```\n *\n * @param x The input tensor. Must be of dtype 'bool'.\n */\n\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\n\nfunction logicalNot_(x) {\n  const $x = convertToTensor(x, 'x', 'logicalNot', 'bool');\n  return ENGINE.runKernelFunc(backend => backend.logicalNot($x), {\n    $x\n  });\n}\n/**\n * Returns the truth value of `a AND b` element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([false, false, true, true], 'bool');\n * const b = tf.tensor1d([false, true, false, true], 'bool');\n *\n * a.logicalAnd(b).print();\n * ```\n *\n * @param a The first input tensor. Must be of dtype bool.\n * @param b The second input tensor. Must be of dtype bool.\n */\n\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\n\n\nfunction logicalAnd_(a, b) {\n  const $a = convertToTensor(a, 'a', 'logicalAnd', 'bool');\n  const $b = convertToTensor(b, 'b', 'logicalAnd', 'bool');\n  assertAndGetBroadcastShape($a.shape, $b.shape);\n  return ENGINE.runKernelFunc(backend => backend.logicalAnd($a, $b), {\n    a: $a,\n    b: $b\n  }, null\n  /* grad */\n  , 'LogicalAnd');\n}\n/**\n * Returns the truth value of `a OR b` element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([false, false, true, true], 'bool');\n * const b = tf.tensor1d([false, true, false, true], 'bool');\n *\n * a.logicalOr(b).print();\n * ```\n * @param a The first input tensor. Must be of dtype bool.\n * @param b The second input tensor. Must be of dtype bool.\n */\n\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\n\n\nfunction logicalOr_(a, b) {\n  const $a = convertToTensor(a, 'a', 'logicalOr', 'bool');\n  const $b = convertToTensor(b, 'b', 'logicalOr', 'bool');\n  assertAndGetBroadcastShape($a.shape, $b.shape);\n  return ENGINE.runKernelFunc(backend => backend.logicalOr($a, $b), {\n    $a,\n    $b\n  });\n}\n/**\n * Returns the truth value of `a XOR b` element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([false, false, true, true], 'bool');\n * const b = tf.tensor1d([false, true, false, true], 'bool');\n *\n * a.logicalXor(b).print();\n * ```\n *\n * @param a The first input tensor. Must be of dtype bool.\n * @param b The second input tensor. Must be of dtype bool.\n */\n\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\n\n\nfunction logicalXor_(a, b) {\n  const $a = convertToTensor(a, 'a', 'logicalXor', 'bool');\n  const $b = convertToTensor(b, 'b', 'logicalXor', 'bool');\n  assertAndGetBroadcastShape($a.shape, $b.shape); // x ^ y = (x | y) & ~(x & y)\n\n  return logicalOr(a, b).logicalAnd(logicalAnd(a, b).logicalNot());\n}\n/**\n * Returns the elements, either `a` or `b` depending on the `condition`.\n *\n * If the condition is true, select from `a`, otherwise select from `b`.\n *\n * ```js\n * const cond = tf.tensor1d([false, false, true], 'bool');\n * const a = tf.tensor1d([1 , 2, 3]);\n * const b = tf.tensor1d([-1, -2, -3]);\n *\n * a.where(cond, b).print();\n * ```\n *\n * @param condition The input condition. Must be of dtype bool.\n * @param a If `condition` is rank 1, `a` may have a higher rank but\n *     its first dimension must match the size of `condition`.\n * @param b A tensor with the same shape and type as `a`.\n */\n\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\n\n\nfunction where_(condition, a, b) {\n  const $a = convertToTensor(a, 'a', 'where');\n  const $b = convertToTensor(b, 'b', 'where');\n  const $condition = convertToTensor(condition, 'condition', 'where', 'bool');\n  assertShapesMatch($a.shape, $b.shape, 'Error in where: ');\n\n  if ($condition.rank === 1) {\n    // If condition rank is 1, then the first dimension must match the size of\n    // condition.\n    assert($condition.shape[0] === $a.shape[0], () => 'The first dimension of `a` must match the size of `condition`.');\n  } else {\n    // A must have the same shape as condition.\n    assertShapesMatch($condition.shape, $b.shape, 'Error in where: ');\n  } // TODO(julianoks): Return null for condition gradient\n  // when backprop supports it.\n\n\n  const grad = (dy, saved) => {\n    const [$condition] = saved;\n    return {\n      condition: () => zerosLike($condition).toFloat(),\n      t: () => dy.mul($condition.cast(dy.dtype)),\n      e: () => dy.mul($condition.logicalNot().cast(dy.dtype))\n    };\n  };\n\n  const inputs = {\n    condition: $condition,\n    t: $a,\n    e: $b\n  };\n  return ENGINE.runKernelFunc((backend, save) => {\n    const res = backend.select($condition, $a, $b);\n    save([$condition]);\n    return res;\n  }, inputs, grad, SelectV2);\n}\n/**\n * Returns the coordinates of true elements of condition.\n *\n * The coordinates are returned in a 2-D tensor where the first dimension (rows)\n * represents the number of true elements, and the second dimension (columns)\n * represents the coordinates of the true elements. Keep in mind, the shape of\n * the output tensor can vary depending on how many true values there are in\n * input. Indices are output in row-major order. The resulting tensor has the\n * shape `[numTrueElems, condition.rank]`.\n *\n * This is analogous to calling the python `tf.where(cond)` without an x or y.\n *\n * ```js\n * const cond = tf.tensor1d([false, false, true], 'bool');\n * const result = await tf.whereAsync(cond);\n * result.print();\n * ```\n */\n\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\n\n\nasync function whereAsync_(condition) {\n  const $condition = convertToTensor(condition, 'condition', 'whereAsync', 'bool');\n  const vals = await $condition.data();\n  const res = whereImpl($condition.shape, vals);\n\n  if (condition !== $condition) {\n    $condition.dispose();\n  }\n\n  return res;\n}\n\nexport const logicalAnd = op({\n  logicalAnd_\n});\nexport const logicalNot = op({\n  logicalNot_\n});\nexport const logicalOr = op({\n  logicalOr_\n});\nexport const logicalXor = op({\n  logicalXor_\n});\nexport const where = op({\n  where_\n});\nexport const whereAsync = whereAsync_;","map":{"version":3,"sources":["../../src/ops/logical_ops.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQ,SAAR,QAAwB,wBAAxB;AACA,SAAQ,MAAR,QAAqB,WAArB;AACA,SAAQ,QAAR,QAAuC,iBAAvC;AAGA,SAAQ,eAAR,QAA8B,oBAA9B;AAEA,SAAQ,MAAR,EAAgB,iBAAhB,QAAwC,SAAxC;AAEA,SAAQ,0BAAR,QAAyC,kBAAzC;AACA,SAAQ,EAAR,QAAiB,aAAjB;AACA,SAAQ,SAAR,QAAwB,cAAxB;AAEA;;;;;;;;;;;;AAWA;;AACA,SAAS,WAAT,CAAuC,CAAvC,EAAsD;AACpD,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,YAAT,EAAuB,MAAvB,CAA1B;AACA,SAAO,MAAM,CAAC,aAAP,CAAqB,OAAO,IAAI,OAAO,CAAC,UAAR,CAAmB,EAAnB,CAAhC,EAAwD;AAAC,IAAA;AAAD,GAAxD,CAAP;AACD;AAED;;;;;;;;;;;;;;AAaA;;;AACA,SAAS,WAAT,CACI,CADJ,EAC0B,CAD1B,EAC8C;AAC5C,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,YAAT,EAAuB,MAAvB,CAA1B;AACA,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,YAAT,EAAuB,MAAvB,CAA1B;AACA,EAAA,0BAA0B,CAAC,EAAE,CAAC,KAAJ,EAAW,EAAE,CAAC,KAAd,CAA1B;AAEA,SAAO,MAAM,CAAC,aAAP,CACI,OAAO,IAAI,OAAO,CAAC,UAAR,CAAmB,EAAnB,EAAuB,EAAvB,CADf,EAC2C;AAAC,IAAA,CAAC,EAAE,EAAJ;AAAQ,IAAA,CAAC,EAAE;AAAX,GAD3C,EAEI;AAAK;AAFT,IAEqB,YAFrB,CAAP;AAGD;AAED;;;;;;;;;;;;;AAYA;;;AACA,SAAS,UAAT,CACI,CADJ,EAC0B,CAD1B,EAC8C;AAC5C,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,WAAT,EAAsB,MAAtB,CAA1B;AACA,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,WAAT,EAAsB,MAAtB,CAA1B;AACA,EAAA,0BAA0B,CAAC,EAAE,CAAC,KAAJ,EAAW,EAAE,CAAC,KAAd,CAA1B;AAEA,SAAO,MAAM,CAAC,aAAP,CAAqB,OAAO,IAAI,OAAO,CAAC,SAAR,CAAkB,EAAlB,EAAsB,EAAtB,CAAhC,EAA2D;AAAC,IAAA,EAAD;AAAK,IAAA;AAAL,GAA3D,CAAP;AAED;AAED;;;;;;;;;;;;;;AAaA;;;AACA,SAAS,WAAT,CACI,CADJ,EAC0B,CAD1B,EAC8C;AAC5C,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,YAAT,EAAuB,MAAvB,CAA1B;AACA,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,YAAT,EAAuB,MAAvB,CAA1B;AACA,EAAA,0BAA0B,CAAC,EAAE,CAAC,KAAJ,EAAW,EAAE,CAAC,KAAd,CAA1B,CAH4C,CAK5C;;AACA,SAAO,SAAS,CAAC,CAAD,EAAI,CAAJ,CAAT,CAAgB,UAAhB,CAA2B,UAAU,CAAC,CAAD,EAAI,CAAJ,CAAV,CAAiB,UAAjB,EAA3B,CAAP;AACD;AAED;;;;;;;;;;;;;;;;;;;AAkBA;;;AACA,SAAS,MAAT,CACI,SADJ,EACkC,CADlC,EACmD,CADnD,EACkE;AAChE,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,OAAT,CAA1B;AACA,QAAM,EAAE,GAAG,eAAe,CAAC,CAAD,EAAI,GAAJ,EAAS,OAAT,CAA1B;AACA,QAAM,UAAU,GAAG,eAAe,CAAC,SAAD,EAAY,WAAZ,EAAyB,OAAzB,EAAkC,MAAlC,CAAlC;AAEA,EAAA,iBAAiB,CAAC,EAAE,CAAC,KAAJ,EAAW,EAAE,CAAC,KAAd,EAAqB,kBAArB,CAAjB;;AAEA,MAAI,UAAU,CAAC,IAAX,KAAoB,CAAxB,EAA2B;AACzB;AACA;AACA,IAAA,MAAM,CACF,UAAU,CAAC,KAAX,CAAiB,CAAjB,MAAwB,EAAE,CAAC,KAAH,CAAS,CAAT,CADtB,EAEF,MAAM,gEAFJ,CAAN;AAGD,GAND,MAMO;AACL;AACA,IAAA,iBAAiB,CAAC,UAAU,CAAC,KAAZ,EAAmB,EAAE,CAAC,KAAtB,EAA6B,kBAA7B,CAAjB;AACD,GAhB+D,CAkBhE;AACA;;;AACA,QAAM,IAAI,GAAG,CAAC,EAAD,EAAQ,KAAR,KAA2B;AACtC,UAAM,CAAC,UAAD,IAAe,KAArB;AACA,WAAO;AACL,MAAA,SAAS,EAAE,MAAM,SAAS,CAAC,UAAD,CAAT,CAAsB,OAAtB,EADZ;AAEL,MAAA,CAAC,EAAE,MAAM,EAAE,CAAC,GAAH,CAAO,UAAU,CAAC,IAAX,CAAgB,EAAE,CAAC,KAAnB,CAAP,CAFJ;AAGL,MAAA,CAAC,EAAE,MAAM,EAAE,CAAC,GAAH,CAAO,UAAU,CAAC,UAAX,GAAwB,IAAxB,CAA6B,EAAE,CAAC,KAAhC,CAAP;AAHJ,KAAP;AAKD,GAPD;;AASA,QAAM,MAAM,GAAmB;AAAC,IAAA,SAAS,EAAE,UAAZ;AAAwB,IAAA,CAAC,EAAE,EAA3B;AAA+B,IAAA,CAAC,EAAE;AAAlC,GAA/B;AACA,SAAO,MAAM,CAAC,aAAP,CAAqB,CAAC,OAAD,EAAU,IAAV,KAAkB;AAC5C,UAAM,GAAG,GAAG,OAAO,CAAC,MAAR,CAAe,UAAf,EAA2B,EAA3B,EAA+B,EAA/B,CAAZ;AACA,IAAA,IAAI,CAAC,CAAC,UAAD,CAAD,CAAJ;AACA,WAAO,GAAP;AACD,GAJM,EAIJ,MAJI,EAIiC,IAJjC,EAIuC,QAJvC,CAAP;AAKD;AAED;;;;;;;;;;;;;;;;;;;AAkBA;;;AACA,eAAe,WAAf,CAA2B,SAA3B,EAAuD;AACrD,QAAM,UAAU,GACZ,eAAe,CAAC,SAAD,EAAY,WAAZ,EAAyB,YAAzB,EAAuC,MAAvC,CADnB;AAEA,QAAM,IAAI,GAAG,MAAM,UAAU,CAAC,IAAX,EAAnB;AACA,QAAM,GAAG,GAAG,SAAS,CAAC,UAAU,CAAC,KAAZ,EAAmB,IAAnB,CAArB;;AACA,MAAI,SAAS,KAAK,UAAlB,EAA8B;AAC5B,IAAA,UAAU,CAAC,OAAX;AACD;;AACD,SAAO,GAAP;AACD;;AAED,OAAO,MAAM,UAAU,GAAG,EAAE,CAAC;AAAC,EAAA;AAAD,CAAD,CAArB;AACP,OAAO,MAAM,UAAU,GAAG,EAAE,CAAC;AAAC,EAAA;AAAD,CAAD,CAArB;AACP,OAAO,MAAM,SAAS,GAAG,EAAE,CAAC;AAAC,EAAA;AAAD,CAAD,CAApB;AACP,OAAO,MAAM,UAAU,GAAG,EAAE,CAAC;AAAC,EAAA;AAAD,CAAD,CAArB;AACP,OAAO,MAAM,KAAK,GAAG,EAAE,CAAC;AAAC,EAAA;AAAD,CAAD,CAAhB;AACP,OAAO,MAAM,UAAU,GAAG,WAAnB","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { whereImpl } from '../backends/where_impl';\nimport { ENGINE } from '../engine';\nimport { SelectV2 } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { assert, assertShapesMatch } from '../util';\nimport { assertAndGetBroadcastShape } from './broadcast_util';\nimport { op } from './operation';\nimport { zerosLike } from './tensor_ops';\n/**\n * Returns the truth value of `NOT x` element-wise.\n *\n * ```js\n * const a = tf.tensor1d([false, true], 'bool');\n *\n * a.logicalNot().print();\n * ```\n *\n * @param x The input tensor. Must be of dtype 'bool'.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction logicalNot_(x) {\n    const $x = convertToTensor(x, 'x', 'logicalNot', 'bool');\n    return ENGINE.runKernelFunc(backend => backend.logicalNot($x), { $x });\n}\n/**\n * Returns the truth value of `a AND b` element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([false, false, true, true], 'bool');\n * const b = tf.tensor1d([false, true, false, true], 'bool');\n *\n * a.logicalAnd(b).print();\n * ```\n *\n * @param a The first input tensor. Must be of dtype bool.\n * @param b The second input tensor. Must be of dtype bool.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction logicalAnd_(a, b) {\n    const $a = convertToTensor(a, 'a', 'logicalAnd', 'bool');\n    const $b = convertToTensor(b, 'b', 'logicalAnd', 'bool');\n    assertAndGetBroadcastShape($a.shape, $b.shape);\n    return ENGINE.runKernelFunc(backend => backend.logicalAnd($a, $b), { a: $a, b: $b }, null /* grad */, 'LogicalAnd');\n}\n/**\n * Returns the truth value of `a OR b` element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([false, false, true, true], 'bool');\n * const b = tf.tensor1d([false, true, false, true], 'bool');\n *\n * a.logicalOr(b).print();\n * ```\n * @param a The first input tensor. Must be of dtype bool.\n * @param b The second input tensor. Must be of dtype bool.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction logicalOr_(a, b) {\n    const $a = convertToTensor(a, 'a', 'logicalOr', 'bool');\n    const $b = convertToTensor(b, 'b', 'logicalOr', 'bool');\n    assertAndGetBroadcastShape($a.shape, $b.shape);\n    return ENGINE.runKernelFunc(backend => backend.logicalOr($a, $b), { $a, $b });\n}\n/**\n * Returns the truth value of `a XOR b` element-wise. Supports broadcasting.\n *\n * ```js\n * const a = tf.tensor1d([false, false, true, true], 'bool');\n * const b = tf.tensor1d([false, true, false, true], 'bool');\n *\n * a.logicalXor(b).print();\n * ```\n *\n * @param a The first input tensor. Must be of dtype bool.\n * @param b The second input tensor. Must be of dtype bool.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction logicalXor_(a, b) {\n    const $a = convertToTensor(a, 'a', 'logicalXor', 'bool');\n    const $b = convertToTensor(b, 'b', 'logicalXor', 'bool');\n    assertAndGetBroadcastShape($a.shape, $b.shape);\n    // x ^ y = (x | y) & ~(x & y)\n    return logicalOr(a, b).logicalAnd(logicalAnd(a, b).logicalNot());\n}\n/**\n * Returns the elements, either `a` or `b` depending on the `condition`.\n *\n * If the condition is true, select from `a`, otherwise select from `b`.\n *\n * ```js\n * const cond = tf.tensor1d([false, false, true], 'bool');\n * const a = tf.tensor1d([1 , 2, 3]);\n * const b = tf.tensor1d([-1, -2, -3]);\n *\n * a.where(cond, b).print();\n * ```\n *\n * @param condition The input condition. Must be of dtype bool.\n * @param a If `condition` is rank 1, `a` may have a higher rank but\n *     its first dimension must match the size of `condition`.\n * @param b A tensor with the same shape and type as `a`.\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nfunction where_(condition, a, b) {\n    const $a = convertToTensor(a, 'a', 'where');\n    const $b = convertToTensor(b, 'b', 'where');\n    const $condition = convertToTensor(condition, 'condition', 'where', 'bool');\n    assertShapesMatch($a.shape, $b.shape, 'Error in where: ');\n    if ($condition.rank === 1) {\n        // If condition rank is 1, then the first dimension must match the size of\n        // condition.\n        assert($condition.shape[0] === $a.shape[0], () => 'The first dimension of `a` must match the size of `condition`.');\n    }\n    else {\n        // A must have the same shape as condition.\n        assertShapesMatch($condition.shape, $b.shape, 'Error in where: ');\n    }\n    // TODO(julianoks): Return null for condition gradient\n    // when backprop supports it.\n    const grad = (dy, saved) => {\n        const [$condition] = saved;\n        return {\n            condition: () => zerosLike($condition).toFloat(),\n            t: () => dy.mul($condition.cast(dy.dtype)),\n            e: () => dy.mul($condition.logicalNot().cast(dy.dtype))\n        };\n    };\n    const inputs = { condition: $condition, t: $a, e: $b };\n    return ENGINE.runKernelFunc((backend, save) => {\n        const res = backend.select($condition, $a, $b);\n        save([$condition]);\n        return res;\n    }, inputs, grad, SelectV2);\n}\n/**\n * Returns the coordinates of true elements of condition.\n *\n * The coordinates are returned in a 2-D tensor where the first dimension (rows)\n * represents the number of true elements, and the second dimension (columns)\n * represents the coordinates of the true elements. Keep in mind, the shape of\n * the output tensor can vary depending on how many true values there are in\n * input. Indices are output in row-major order. The resulting tensor has the\n * shape `[numTrueElems, condition.rank]`.\n *\n * This is analogous to calling the python `tf.where(cond)` without an x or y.\n *\n * ```js\n * const cond = tf.tensor1d([false, false, true], 'bool');\n * const result = await tf.whereAsync(cond);\n * result.print();\n * ```\n */\n/** @doc {heading: 'Operations', subheading: 'Logical'} */\nasync function whereAsync_(condition) {\n    const $condition = convertToTensor(condition, 'condition', 'whereAsync', 'bool');\n    const vals = await $condition.data();\n    const res = whereImpl($condition.shape, vals);\n    if (condition !== $condition) {\n        $condition.dispose();\n    }\n    return res;\n}\nexport const logicalAnd = op({ logicalAnd_ });\nexport const logicalNot = op({ logicalNot_ });\nexport const logicalOr = op({ logicalOr_ });\nexport const logicalXor = op({ logicalXor_ });\nexport const where = op({ where_ });\nexport const whereAsync = whereAsync_;\n//# sourceMappingURL=logical_ops.js.map"]},"metadata":{},"sourceType":"module"}