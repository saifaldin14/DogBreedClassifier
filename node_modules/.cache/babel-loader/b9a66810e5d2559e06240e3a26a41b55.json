{"ast":null,"code":"/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { scalar, tensor1d, zeros } from '../ops/tensor_ops';\nimport { hasEncodingLoss, makeZerosTypedArray } from '../util'; // Utilities needed by backend consumers of tf-core.\n\nexport * from '../ops/axis_util';\nexport * from '../ops/broadcast_util';\nexport * from '../ops/concat_util';\nexport * from '../ops/conv_util';\nexport * from '../ops/reduce_util';\nexport { nonMaxSuppressionV3, nonMaxSuppressionV5 } from './non_max_suppression_impl';\nexport { upcastType } from '../types';\nexport * from '../ops/array_ops_util';\nexport * from '../ops/gather_nd_util';\nexport * from '../ops/scatter_nd_util';\nexport * from '../ops/selu_util';\nexport * from '../ops/fused_util';\nexport * from '../ops/erf_util';\nexport * from '../log';\nexport * from '../backends/complex_util';\nimport * as segment_util from '../ops/segment_util';\nexport { segment_util };\nexport function castTensor(x, dtype, backend) {\n  if (dtype === 'complex64') {\n    if (x.dtype === 'complex64') {\n      return x.clone();\n    }\n\n    const zerosTensor = zeros(x.shape);\n    const floatX = x.toFloat();\n    const result = backend.complex(floatX, zerosTensor);\n    zerosTensor.dispose();\n    floatX.dispose();\n    return result;\n  }\n\n  if (!hasEncodingLoss(x.dtype, dtype)) {\n    // We don't change the underlying data, since we cast to higher\n    // precision.\n    return ENGINE.makeTensorFromDataId(x.dataId, x.shape, dtype);\n  }\n\n  if (x.dtype === 'complex64') {\n    const real = backend.real(x);\n    const result = real.cast(dtype);\n    real.dispose();\n    return result;\n  }\n\n  if (dtype === 'int32') {\n    return backend.int(x);\n  } else if (dtype === 'bool') {\n    const zero = scalar(0, x.dtype);\n    const result = backend.notEqual(x, zero);\n    zero.dispose();\n    return result;\n  } else {\n    throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);\n  }\n}\nexport function reshapeTensor(x, shape) {\n  return ENGINE.makeTensorFromDataId(x.dataId, shape, x.dtype);\n}\nexport function linspaceImpl(start, stop, num) {\n  const step = (stop - start) / (num - 1);\n  const values = makeZerosTypedArray(num, 'float32');\n  values[0] = start;\n\n  for (let i = 1; i < values.length; i++) {\n    values[i] = values[i - 1] + step;\n  }\n\n  return tensor1d(values, 'float32');\n}","map":{"version":3,"sources":["../../src/backends/backend_util.ts"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQ,MAAR,QAAqB,WAArB;AACA,SAAQ,MAAR,EAAgB,QAAhB,EAA0B,KAA1B,QAAsC,mBAAtC;AAIA,SAAQ,eAAR,EAAyB,mBAAzB,QAAmD,SAAnD,C,CAIA;;AACA,cAAc,kBAAd;AACA,cAAc,uBAAd;AACA,cAAc,oBAAd;AACA,cAAc,kBAAd;AAEA,cAAc,oBAAd;AACA,SAAQ,mBAAR,EAA6B,mBAA7B,QAAuD,4BAAvD;AAEA,SAAmC,UAAnC,QAA+D,UAA/D;AAEA,cAAc,uBAAd;AACA,cAAc,uBAAd;AACA,cAAc,wBAAd;AACA,cAAc,kBAAd;AACA,cAAc,mBAAd;AACA,cAAc,iBAAd;AACA,cAAc,QAAd;AACA,cAAc,0BAAd;AAEA,OAAO,KAAK,YAAZ,MAA8B,qBAA9B;AACA,SAAQ,YAAR;AAEA,OAAM,SAAU,UAAV,CACF,CADE,EACI,KADJ,EACqB,OADrB,EAC2C;AAC/C,MAAI,KAAK,KAAK,WAAd,EAA2B;AACzB,QAAI,CAAC,CAAC,KAAF,KAAY,WAAhB,EAA6B;AAC3B,aAAO,CAAC,CAAC,KAAF,EAAP;AACD;;AACD,UAAM,WAAW,GAAG,KAAK,CAAC,CAAC,CAAC,KAAH,CAAzB;AACA,UAAM,MAAM,GAAG,CAAC,CAAC,OAAF,EAAf;AACA,UAAM,MAAM,GAAG,OAAO,CAAC,OAAR,CAAgB,MAAhB,EAAwB,WAAxB,CAAf;AACA,IAAA,WAAW,CAAC,OAAZ;AACA,IAAA,MAAM,CAAC,OAAP;AACA,WAAO,MAAP;AACD;;AAED,MAAI,CAAC,eAAe,CAAC,CAAC,CAAC,KAAH,EAAU,KAAV,CAApB,EAAsC;AACpC;AACA;AACA,WAAO,MAAM,CAAC,oBAAP,CAA4B,CAAC,CAAC,MAA9B,EAAsC,CAAC,CAAC,KAAxC,EAA+C,KAA/C,CAAP;AACD;;AACD,MAAI,CAAC,CAAC,KAAF,KAAY,WAAhB,EAA6B;AAC3B,UAAM,IAAI,GAAG,OAAO,CAAC,IAAR,CAAa,CAAb,CAAb;AACA,UAAM,MAAM,GAAG,IAAI,CAAC,IAAL,CAAU,KAAV,CAAf;AACA,IAAA,IAAI,CAAC,OAAL;AACA,WAAO,MAAP;AACD;;AACD,MAAI,KAAK,KAAK,OAAd,EAAuB;AACrB,WAAO,OAAO,CAAC,GAAR,CAAY,CAAZ,CAAP;AACD,GAFD,MAEO,IAAI,KAAK,KAAK,MAAd,EAAsB;AAC3B,UAAM,IAAI,GAAG,MAAM,CAAC,CAAD,EAAI,CAAC,CAAC,KAAN,CAAnB;AACA,UAAM,MAAM,GAAG,OAAO,CAAC,QAAR,CAAiB,CAAjB,EAAoB,IAApB,CAAf;AACA,IAAA,IAAI,CAAC,OAAL;AACA,WAAO,MAAP;AACD,GALM,MAKA;AACL,UAAM,IAAI,KAAJ,CAAU,iCAAiC,CAAC,CAAC,KAAK,OAAO,KAAK,EAA9D,CAAN;AACD;AACF;AAED,OAAM,SAAU,aAAV,CACF,CADE,EACI,KADJ,EACsB;AAC1B,SAAO,MAAM,CAAC,oBAAP,CAA4B,CAAC,CAAC,MAA9B,EAAsC,KAAtC,EAA6C,CAAC,CAAC,KAA/C,CAAP;AACD;AAED,OAAM,SAAU,YAAV,CAAuB,KAAvB,EAAsC,IAAtC,EAAoD,GAApD,EAA+D;AACnE,QAAM,IAAI,GAAG,CAAC,IAAI,GAAG,KAAR,KAAkB,GAAG,GAAG,CAAxB,CAAb;AAEA,QAAM,MAAM,GAAG,mBAAmB,CAAC,GAAD,EAAM,SAAN,CAAlC;AACA,EAAA,MAAM,CAAC,CAAD,CAAN,GAAY,KAAZ;;AACA,OAAK,IAAI,CAAC,GAAG,CAAb,EAAgB,CAAC,GAAG,MAAM,CAAC,MAA3B,EAAmC,CAAC,EAApC,EAAwC;AACtC,IAAA,MAAM,CAAC,CAAD,CAAN,GAAY,MAAM,CAAC,CAAC,GAAG,CAAL,CAAN,GAAgB,IAA5B;AACD;;AAED,SAAO,QAAQ,CAAC,MAAD,EAAS,SAAT,CAAf;AACD","sourceRoot":"","sourcesContent":["/**\n * @license\n * Copyright 2018 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { scalar, tensor1d, zeros } from '../ops/tensor_ops';\nimport { hasEncodingLoss, makeZerosTypedArray } from '../util';\n// Utilities needed by backend consumers of tf-core.\nexport * from '../ops/axis_util';\nexport * from '../ops/broadcast_util';\nexport * from '../ops/concat_util';\nexport * from '../ops/conv_util';\nexport * from '../ops/reduce_util';\nexport { nonMaxSuppressionV3, nonMaxSuppressionV5 } from './non_max_suppression_impl';\nexport { upcastType } from '../types';\nexport * from '../ops/array_ops_util';\nexport * from '../ops/gather_nd_util';\nexport * from '../ops/scatter_nd_util';\nexport * from '../ops/selu_util';\nexport * from '../ops/fused_util';\nexport * from '../ops/erf_util';\nexport * from '../log';\nexport * from '../backends/complex_util';\nimport * as segment_util from '../ops/segment_util';\nexport { segment_util };\nexport function castTensor(x, dtype, backend) {\n    if (dtype === 'complex64') {\n        if (x.dtype === 'complex64') {\n            return x.clone();\n        }\n        const zerosTensor = zeros(x.shape);\n        const floatX = x.toFloat();\n        const result = backend.complex(floatX, zerosTensor);\n        zerosTensor.dispose();\n        floatX.dispose();\n        return result;\n    }\n    if (!hasEncodingLoss(x.dtype, dtype)) {\n        // We don't change the underlying data, since we cast to higher\n        // precision.\n        return ENGINE.makeTensorFromDataId(x.dataId, x.shape, dtype);\n    }\n    if (x.dtype === 'complex64') {\n        const real = backend.real(x);\n        const result = real.cast(dtype);\n        real.dispose();\n        return result;\n    }\n    if (dtype === 'int32') {\n        return backend.int(x);\n    }\n    else if (dtype === 'bool') {\n        const zero = scalar(0, x.dtype);\n        const result = backend.notEqual(x, zero);\n        zero.dispose();\n        return result;\n    }\n    else {\n        throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);\n    }\n}\nexport function reshapeTensor(x, shape) {\n    return ENGINE.makeTensorFromDataId(x.dataId, shape, x.dtype);\n}\nexport function linspaceImpl(start, stop, num) {\n    const step = (stop - start) / (num - 1);\n    const values = makeZerosTypedArray(num, 'float32');\n    values[0] = start;\n    for (let i = 1; i < values.length; i++) {\n        values[i] = values[i - 1] + step;\n    }\n    return tensor1d(values, 'float32');\n}\n//# sourceMappingURL=backend_util.js.map"]},"metadata":{},"sourceType":"module"}